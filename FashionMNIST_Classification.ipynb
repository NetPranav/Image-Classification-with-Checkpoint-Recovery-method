{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4694443c-d15e-4b39-889c-1c7142f76405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03970c6-b31d-4c54-a0a3-5425f37a5cc0",
   "metadata": {},
   "source": [
    "## Device Agnostic Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25d5bf54-b952-4c19-b8c1-4f79f0b1fff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65096e4-c723-4121-8e23-7607a6c66bb3",
   "metadata": {},
   "source": [
    "## Setting up Transformer and Augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1907ed46-6d21-4c44-9779-e7c6e658f119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Define the transformation pipeline\n",
    "transformer = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Randomly flip the image with 50% probability\n",
    "    transforms.ToTensor()  # Convert the image to a tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2647a82-ad4a-4f94-a73f-6b6aeeae41b2",
   "metadata": {},
   "source": [
    "## Download the FashionMNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8970a318-9cc0-4973-9087-6a06f913f5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "train_data = torchvision.datasets.FashionMNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform =transformer\n",
    ")\n",
    "test_data = torchvision.datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = transformer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1df477-fddb-4900-b47e-9dd895d2a2d7",
   "metadata": {},
   "source": [
    "## Getting instance of random Data(for easier Visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42c0eec0-eb96-40c2-9f22-913fb022515d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random_data = random.randint(0,len(train_data)-1)\n",
    "\n",
    "images,label = train_data[random_data]\n",
    "images.shape,label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef74935-c503-4c71-b1e5-11816494fa38",
   "metadata": {},
   "source": [
    "## Converting to DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de23e915-2db5-45d7-a88b-d9bf3faf512c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import os \n",
    "\n",
    "Batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(batch_size=Batch_size,dataset = train_data,shuffle = False)\n",
    "test_dataloader = DataLoader(batch_size = Batch_size,dataset = test_data,shuffle = True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075e513f-0215-4829-b811-bd01bee29572",
   "metadata": {},
   "source": [
    "## Getting the visulaization of the data os instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ebb3d7f-f3b3-4164-a675-456a86abf193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize = (10,5))\n",
    "plt.imshow(images.squeeze())\n",
    "plt.title(f\"transformed : {train_data.classes[label]}\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9e4cac-9562-48a0-83ba-b076dfd5e5b4",
   "metadata": {},
   "source": [
    "## Making the two Model to train the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c63aef88-ca27-4eff-9cc1-f9a415f0fca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# simple multilayer percepetron (MLP)\n",
    "class model_linear(nn.Module):\n",
    "    def __init__(self,\n",
    "                input:int,       # input size (28*28 = 784 for FashionMNIST)\n",
    "                hidden_units_1:int,\n",
    "                hidden_units_2:int,\n",
    "                output:int):     # output size (10 classes for FashionMNIST)\n",
    "        super().__init__()\n",
    "        \n",
    "        self.flatten = nn.Flatten()  # Flatten the input image\n",
    "        self.linear_layer_1 = nn.Sequential(\n",
    "            nn.Linear(in_features=input, out_features=hidden_units_1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units_1, out_features=hidden_units_2)\n",
    "        )\n",
    "        self.linear_layer_2 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_units_2, out_features=hidden_units_1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units_1, out_features=hidden_units_2)\n",
    "        )\n",
    "        self.linear_layer_3 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_units_2, out_features=hidden_units_1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units_1, out_features=output)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_layer_3(self.linear_layer_2(self.linear_layer_1(self.flatten(x))))\n",
    "\n",
    "\n",
    "# Simple CNN\n",
    "class model_CNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                input:int,\n",
    "                hidden_units:int,\n",
    "                output:int):\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=input,\n",
    "                  out_channels = hidden_units,\n",
    "                  kernel_size = 3,\n",
    "                  stride = 1,\n",
    "                  padding = 1), # values we can set ourself in our NN's are called hyperparameter\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels = hidden_units,\n",
    "                  out_channels = hidden_units,\n",
    "                  kernel_size = 3,\n",
    "                  stride = 1,\n",
    "                  padding = 1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size = 2)\n",
    "        )\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = hidden_units,\n",
    "                      out_channels = hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride = 1,\n",
    "                      padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels = hidden_units,\n",
    "                      out_channels = hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride = 1,\n",
    "                      padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(in_features=hidden_units*7*7,\n",
    "                  out_features=output)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.classifier(self.conv_block_2(self.conv_block_1(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8918a1ff-e44d-40c5-b515-ce6447bc65a7",
   "metadata": {},
   "source": [
    "## Making the Instances of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7404985c-7009-48cc-a716-2c549d99e05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Linear_model = model_linear(input = 28*28,\n",
    "                           hidden_units_1 = 10,\n",
    "                           hidden_units_2 = 20,\n",
    "                           output = len(train_data.classes)).to(device)\n",
    "CNN_model = model_CNN(input= 1,\n",
    "                     hidden_units = 8,\n",
    "                     output = len(train_data.classes)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45ba4f1e-c185-4423-8b60-ca185e81e822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data.classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acbde53-d5c3-4b26-8fe2-de4b144a4203",
   "metadata": {},
   "source": [
    "## Loss function Optimizer and accuracy_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be46d962-4aeb-4d1a-8b3c-067b4aa5f7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model = CNN_model\n",
    "optimizer_Linear = torch.optim.SGD(model.parameters(),lr=0.01)\n",
    "optimizer_CNN = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "def accuracy_fn(y_pred,y_true):\n",
    "  correct = torch.eq(y_pred,y_true).sum().item()\n",
    "  acc = (correct/len(y_true))*100\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa53228b-b508-4a5a-b3ed-58b1c1b87126",
   "metadata": {},
   "source": [
    "## Fucntionizing the training testing and evaulating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9085bc9-c2b0-4d3f-8e20-1307966e61c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" \n",
    "def train_model(model: torch.nn.Module,\n",
    "                data_loader : torch.utils.data.DataLoader,\n",
    "                loss_fn: torch.nn.Module,\n",
    "                optimizer: torch.optim.Optimizer,\n",
    "                accuracy_fn,\n",
    "                device : torch.device = device\n",
    "                ):\n",
    "    train_loss,train_acc = 0,0\n",
    "    model.train()\n",
    "\n",
    "    for batch,(X,y) in enumerate(data_loader):\n",
    "      X,y = X.to(device),y.to(device)\n",
    "      y_pred = model(X)\n",
    "\n",
    "      loss = loss_fn(y_pred,y)\n",
    "      train_loss += loss\n",
    "      train_acc += accuracy_fn(y_true = y,y_pred = y_pred.argmax(dim=1))\n",
    "  \n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "  \n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f\"train_loss: {train_loss:.5f} | train_acc: {train_acc:.2f}%\")\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def testing_model(model: torch.nn.Module,\n",
    "                  data_loader: torch.utils.data.DataLoader,\n",
    "                  loss_fn: torch.nn.Module,\n",
    "                  accuracy_fn,\n",
    "                  device : torch.device = device):\n",
    "    test_loss,test_acc = 0,0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "      for X_test,y_test in data_loader:\n",
    "        X_test,y_test = X_test.to(device),y_test.to(device)\n",
    "        test_pred = model(X_test)\n",
    "        test_loss += loss_fn(test_pred,y_test)\n",
    "        test_acc += accuracy_fn(y_true = y_test,y_pred = test_pred.argmax(dim=1))\n",
    "      test_loss /= len(data_loader)\n",
    "      test_acc /= len(data_loader)\n",
    "      print(f\"test_loss: {test_loss:.5f} | test_acc: {test_acc:.2f}%\")\n",
    "    return test_loss,test_acc\n",
    "\n",
    "def eval_model(model: torch.nn.Module,\n",
    "               data_loader : torch.utils.data.DataLoader,\n",
    "               loss: torch.nn.Module,\n",
    "               accuracy_fn,\n",
    "               device: torch.device = device):\n",
    "  loss,acc = 0,0\n",
    "  model.eval()\n",
    "  with torch.inference_mode():\n",
    "    for X,y in tqdm(data_loader):\n",
    "      X,y = X.to(device),y.to(device)\n",
    "      y_pred = model(X)\n",
    "\n",
    "      loss = loss_fn(y_pred,y)\n",
    "      acc += accuracy_fn(y_true = y,y_pred = y_pred.argmax(dim= 1))\n",
    "\n",
    "    loss /= len(data_loader)\n",
    "    acc /= len(data_loader)\n",
    "\n",
    "  return {\"model name\": model.__class__.__name__,\n",
    "          \"loss\": loss.item(),\n",
    "          \"acc\": acc}\n",
    "\n",
    "def Train_time(start:float,\n",
    "               end:float,\n",
    "               device: torch.device = None):\n",
    "  total_time = end-start\n",
    "  print(f\"Train time on {device} is {total_time:.3f} seconds\")\n",
    "  return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4daa9a0-4f68-4a16-bbf9-7a654685626a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3e0b875-6e84-49dd-a772-750bed3571bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "MODEL_PATH= Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "# create model save path\n",
    "# saving and loading model\n",
    "MODEL_NAME = \"CNN_Model_state_dict.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH/MODEL_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6b4731-d0f7-4e5d-bb19-d755297cb74d",
   "metadata": {},
   "source": [
    "## Training and Testing Phase of Linear model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f29d553-f1c0-4e0f-bace-855797520617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ...\n",
      "train_loss: 2.31809 | train_acc: 10.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▊                                                                   | 1/5 [00:27<01:48, 27.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 2.31817 | test_acc: 10.00%\n",
      "Train time on cuda is 27.156 seconds\n",
      "Epoch: 1 ...\n",
      "train_loss: 2.31809 | train_acc: 10.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▌                                                  | 2/5 [00:56<01:25, 28.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 2.31818 | test_acc: 9.99%\n",
      "Train time on cuda is 56.349 seconds\n",
      "Epoch: 2 ...\n",
      "train_loss: 2.31809 | train_acc: 10.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [01:25<00:57, 28.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 2.31807 | test_acc: 10.00%\n",
      "Train time on cuda is 85.066 seconds\n",
      "Epoch: 3 ...\n",
      "train_loss: 2.31809 | train_acc: 10.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [01:54<00:28, 28.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 2.31822 | test_acc: 9.98%\n",
      "Train time on cuda is 114.322 seconds\n",
      "Epoch: 4 ...\n",
      "train_loss: 2.31810 | train_acc: 10.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [02:23<00:00, 28.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 2.31797 | test_acc: 10.01%\n",
      "Train time on cuda is 143.047 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "train_time_start_model =timer()\n",
    "epochs = 5\n",
    "for epoch in tqdm(range(epochs)):\n",
    "  print(f\"Epoch: {epoch} ...\")\n",
    "  train_model(model = Linear_model,\n",
    "              data_loader = train_dataloader,\n",
    "              loss_fn = loss_fn,\n",
    "              optimizer = optimizer_Linear,\n",
    "              accuracy_fn = accuracy_fn,\n",
    "              device = device)\n",
    "  testing_model(model = Linear_model,\n",
    "                data_loader = test_dataloader,\n",
    "                loss_fn = loss_fn,\n",
    "                accuracy_fn = accuracy_fn,\n",
    "                device = device)\n",
    "  train_time_end_model = timer()\n",
    "  Train_time(start = train_time_start_model,\n",
    "             end = train_time_end_model,\n",
    "             device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e59d14-e829-4130-97b3-458d22b7429e",
   "metadata": {},
   "source": [
    "## Training and Testing Phase of CNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d39ee7-eab5-432a-8472-6cde61dcbf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded successfully. Starting from epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ...\n",
      "train_loss: 0.19213 | train_acc: 93.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|█████████████████████                                                               | 1/4 [00:34<01:44, 34.88s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.27939 | test_acc: 90.63%\n",
      "Epoch: 1 ...\n",
      "train_loss: 0.18837 | train_acc: 93.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|██████████████████████████████████████████                                          | 2/4 [01:06<01:05, 32.72s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.28068 | test_acc: 90.79%\n",
      "Epoch: 2 ...\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# load the save dict if available\n",
    "try:\n",
    "    checkpoint = torch.load(MODEL_SAVE_PATH)\n",
    "    CNN_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer_CNN.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint.get('epoch', 0)\n",
    "    print(\"Checkpoint loaded successfully. Starting from epoch:\", start_epoch)\n",
    "except FileNotFoundError:\n",
    "    print(f\"No checkpoint found at {MODEL_SAVE_PATH}. Starting training from scratch...\")\n",
    "    start_epoch = 0\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "train_time_start_model =timer()\n",
    "indx = 2\n",
    "epochs = 4\n",
    "\n",
    "#  Results of the model training\n",
    "model_results = {\"train_loss\":[],\n",
    "                \"train_acc\":[],\n",
    "                \"test_loss\":[],\n",
    "                \"test_acc\":[]}\n",
    "\n",
    "for i in tqdm(range(indx)):\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        print(f\"Epoch: {epoch} ...\")\n",
    "        train_loss,train_acc = train_model(model = CNN_model,\n",
    "                    data_loader = train_dataloader,\n",
    "                    loss_fn = loss_fn,\n",
    "                    optimizer = optimizer_CNN,\n",
    "                    accuracy_fn = accuracy_fn,\n",
    "                    device = device)\n",
    "        test_loss,test_acc = testing_model(model = CNN_model,\n",
    "                    data_loader = test_dataloader,\n",
    "                    loss_fn = loss_fn,\n",
    "                    accuracy_fn = accuracy_fn,\n",
    "                    device = device)\n",
    "\n",
    "        model_results[\"train_loss\"].append(train_loss)\n",
    "        model_results[\"train_acc\"].append(train_acc)\n",
    "        model_results[\"test_loss\"].append(test_loss)\n",
    "        model_results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "    torch.save({\n",
    "        'model_state_dict': CNN_model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer_CNN.state_dict(),\n",
    "    }, MODEL_SAVE_PATH)\n",
    "    # loading model\n",
    "    checkpoint = torch.load(MODEL_SAVE_PATH)\n",
    "    CNN_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer_CNN.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "train_time_end_model = timer()\n",
    "Train_time(start = train_time_start_model,\n",
    "     end = train_time_end_model,\n",
    "     device = device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918ea56f-6ab4-4955-887f-9e808b211afc",
   "metadata": {},
   "source": [
    "## Evaluating the models  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64390d33-a20b-417f-8b2c-ead2c7b1b4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model_result = eval_model(model = Linear_model,\n",
    "          data_loader = test_dataloader,\n",
    "          loss = loss_fn,\n",
    "          accuracy_fn = accuracy_fn,\n",
    "          device = device),\n",
    "CNN_model_results = eval_model(model = CNN_model,\n",
    "          data_loader = test_dataloader,\n",
    "          loss = loss_fn,\n",
    "          accuracy_fn = accuracy_fn,\n",
    "          device = device)\n",
    "linear_model_result,CNN_model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722441e5-085e-4fac-8550-518b7971fe89",
   "metadata": {},
   "source": [
    "## Plotting the loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e3efbc-a405-49e1-8567-6fdf5593d2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curve():"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a34dcaa-e8a6-4a43-b1eb-a94dc94ee9ea",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be42959-3db6-4ca9-8b71-75cda134b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing random testing\n",
    "def testing_function(model:torch.nn.Module,\n",
    "                    data:list,\n",
    "                    device: torch.device = device):\n",
    "    pred_probs = []\n",
    "    model.to(device)\n",
    "    with torch.inference_mode():\n",
    "        for sample in data:\n",
    "          sample = torch.unsqueeze(sample,dim=0).to(device)\n",
    "          pred_logit = model(sample)\n",
    "          pred_prob = torch.softmax(pred_logit.squeeze(),dim=0)\n",
    "          pred_probs.append(pred_prob.cpu())\n",
    "        return torch.stack(pred_probs)\n",
    "test_sample = []\n",
    "test_labels =[]\n",
    "for sample,label in random.sample(list(test_data),k=9):\n",
    "    test_sample.append(sample)\n",
    "    test_labels.append(label)\n",
    "\n",
    "# mkaing prediction\n",
    "test_pred = testing_function(model=CNN_model,\n",
    "                            data=test_sample)\n",
    "test_class = test_pred.argmax(dim=1)\n",
    "\n",
    "num = 3\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(test_sample[num].squeeze())\n",
    "pred_label = train_data.classes[test_class[num]]\n",
    "true_label = train_data.classes[test_labels[num]]\n",
    "\n",
    "title_text = f\"Pred: {pred_label} | Truth: {true_label}\"\n",
    "\n",
    "# Set title color based on prediction accuracy\n",
    "if pred_label == true_label:\n",
    "    plt.title(title_text, fontsize=12, color=\"green\")  # Green for correct predictions\n",
    "else:\n",
    "    plt.title(title_text, fontsize=12, color=\"red\")    # Red for incorrect predictions\n",
    "\n",
    "# Hide axis for clarity\n",
    "# plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4639f44b-f2c4-4780-80b6-a67fc0955c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
